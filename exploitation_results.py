import pandas as pd
from sklearn.metrics import mean_absolute_percentage_error
import time
from model_serie_temporelle.sarimax_model_cdm import sarimax_prediction_cdm
start = time.time()



# Charger le fichier CSV
df = pd.read_csv('final_data/sarimax_prediction_rer_b.csv', sep=',', parse_dates=['ds'])

# --- 1. Calcul de la MAPE avec scikit-learn ---
# On filtre pour éviter les divisions par zéro
df_nonzero = df[df['y'] != 0]

# Calcul du MAPE
mape = mean_absolute_percentage_error(df_nonzero['y'], df_nonzero['yhat']) * 100
print(f"MAPE (scikit-learn) : {mape:.2f}%")

# --- 2. Groupement par LIBELLE_ARRET et jour (ds) ---
"""
grouped = df.groupby(['LIBELLE_ARRET', 'ds'])['yhat'].sum().reset_index()
print("\nYhat groupé par arrêt et jour :")
print(grouped)

"""
# --- 3. Yhat total global ---
total_yhat = df['yhat'].sum()
total_y = df['y'].sum()

print(f"Nombre de validations total prédit pdt la CDM de rugby: {total_yhat:,.0f}".replace(',', ' '))
print(f"Nombre réel de validations pdt la CDM de rugby: {total_y:,.0f}".replace(',', ' '))

map_old_year = {
    2015: 23864311,
    2016: 25201884,
    2017: 26451808,
    2018: 26642013,
    2019: 26631863,
    2021: 23797427
}
#Nous avons calculé ces valeurs à partir de la base de données df_rer_b.csv au préalable
for year, value in map_old_year.items():
    print(f"Nombre de validations total prédit en {year} à la même période que la cdm: {value:,.0f}".replace(',', ' '))


print(f"Temps d'exécution : {time.time() - start}")
