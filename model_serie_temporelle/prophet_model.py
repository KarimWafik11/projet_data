import pandas as pd
import numpy as np
import holidays
from prophet import Prophet
from prophet.diagnostics import cross_validation, performance_metrics
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error
from sklearn.preprocessing import MinMaxScaler
from itertools import product
import re


def prophet_prediction(year, arret):
    try:
        # 1. Charger les donnÃ©es
        df = pd.read_csv('final_data/df_all_data.csv', parse_dates=['JOUR'])
    except Exception as e:
        print(f"Erreur lors du chargement du fichier CSV : {e}")
        return None

    # Nettoyer l'arrÃªt demandÃ©
    arret_clean = re.sub(r'\s+', '', re.sub(r'\s*\([^)]*\)', '', str(arret)).replace('-', ''))

    # Nettoyer la colonne LIBELLE_ARRET pour la comparaison
    df['LIBELLE_ARRET_clean'] = df['LIBELLE_ARRET'].apply(
        lambda x: re.sub(r'\s+', '', re.sub(r'\s*\([^)]*\)', '', str(x)).replace('-', ''))
    )

    df = df[df['LIBELLE_ARRET_clean'] == arret_clean].copy()
    
    if df.empty:
        print(f"Aucune donnÃ©e trouvÃ©e pour l'arrÃªt : {arret}")
        return None

    print("DerniÃ¨re date dispo pour cet arrÃªt :", df['JOUR'].max())

    # 2. Renommer pour Prophet
    df = df.rename(columns={'JOUR': 'ds', 'NB_VALD': 'y'})
    df = df[['ds', 'y', 'LIBELLE_ARRET', 'IS_VACANCE']].sort_values('ds')

    # 3. Feature engineering Ã  partir de la date
    df['DAY_OF_WEEK'] = df['ds'].dt.weekday / 6  # normalisÃ© entre 0 et 1
    df['IS_WEEKEND'] = (df['ds'].dt.weekday >= 5).astype(int)

    # DÃ©tection des vacances
    fr_holidays = holidays.France(years=range(2015, 2025))
    vacances_connues = pd.to_datetime(list(fr_holidays.keys()))

    # Ajouter la colonne IS_EVENEMENT
    euro_2016_start = pd.Timestamp('2016-06-10')
    euro_2016_end = pd.Timestamp('2016-07-10')
    cdm_rugby_2023_start = pd.Timestamp('2023-09-08')
    cdm_rugby_2023_end = pd.Timestamp('2023-10-28')

    # Dates Ã©vÃ©nements Stade de France (concerts, foot, rugby)
    evenement_dates = [
        # Concerts majeurs
        '2015-05-23', '2015-05-26',  # AC/DC
        '2017-07-15', '2017-07-16',  # Coldplay
        '2017-07-25',                # U2
        '2018-07-14',                # BeyoncÃ© & Jay-Z
        '2019-06-07', '2019-06-08',  # BTS
        '2022-05-21',                # Indochine
        '2022-07-29',                # Ed Sheeran
        # Football hors Euro
        '2015-11-13',                # France â€“ Allemagne
        '2017-03-28',                # France â€“ Espagne (amical)
        '2017-10-07',                # France â€“ Bulgarie (qualif CM)
        '2017-10-10',                # France â€“ BiÃ©lorussie (qualif CM)
        '2018-03-23',                # France â€“ Colombie (amical)
        '2018-06-09',                # France â€“ USA (amical)
        '2019-06-02',                # France â€“ Bolivie (amical)
        '2019-09-07',                # France â€“ Albanie (qualif Euro)
        '2019-09-10',                # France â€“ Andorre (qualif Euro)
        '2020-09-08',                # France â€“ Croatie (Ligue des nations)
        '2021-06-08',                # France â€“ Bulgarie (amical)
        '2021-09-01',                # France â€“ Bosnie (qualif CM)
        '2021-09-04',                # France â€“ Ukraine (qualif CM)
        '2021-09-07',                # France â€“ Finlande (qualif CM)
        '2022-05-28',                # Finale Ligue des champions
        # Rugby - Six Nations (exemples, Ã  complÃ©ter si besoin)
        '2016-02-06',                # France â€“ Italie
        '2017-02-12',                # France â€“ Ecosse
        '2018-02-03',                # France â€“ Irlande
        '2019-02-01',                # France â€“ Pays de Galles
        '2020-02-02',                # France â€“ Angleterre
        '2021-02-14',                # France â€“ Irlande
        '2022-02-12',                # France â€“ Irlande
        # Rugby - autres
        '2021-11-20',                # France â€“ Nouvelle-ZÃ©lande
        # Finales Top 14 (exemples, Ã  complÃ©ter si besoin)
        '2015-06-13', '2016-06-24', '2017-06-04', '2018-06-02', '2019-06-15', '2021-06-25', '2022-06-24'
    ]
    evenement_dates = set(pd.to_datetime(evenement_dates))

    def is_evenement(date):
        if euro_2016_start <= date <= euro_2016_end:
            return 1
        if cdm_rugby_2023_start <= date <= cdm_rugby_2023_end:
            return 1
        if date in evenement_dates:
            return 1
        return 0

    df['IS_EVENEMENT'] = df['ds'].apply(is_evenement)

    features = ['DAY_OF_WEEK', 'IS_WEEKEND', 'IS_VACANCE', 'IS_EVENEMENT']

    # 4. Logarithmiser la variable cible si dispersion Ã©levÃ©e
    df['y_log'] = np.log1p(df['y'])  # log(1 + y)

    # 5. Normalisation
    y_scaler = MinMaxScaler()
    df['y_scaled'] = y_scaler.fit_transform(df[['y_log']])

    # 6. Filtrer les annÃ©es pour entraÃ®nement
    train_df = df[(df['ds'].dt.year >= 2015) & (df['ds'].dt.year <= 2022)]

    # VÃ©rification du nombre de lignes pour Prophet
    if train_df.dropna().shape[0] < 2:
        print(f"â›” Pas assez de donnÃ©es pour entraÃ®ner Prophet pour l'arrÃªt '{arret}'.")
        return None

    # Jours fÃ©riÃ©s pour Prophet
    holidays_df = pd.DataFrame({
        'ds': pd.to_datetime(list(fr_holidays.keys())),
        'holiday': 'fr_holiday'
    })

    # 7. ModÃ¨le Prophet avec rÃ©gressseurs
    m = Prophet(
        holidays=holidays_df,
        yearly_seasonality=True,
        weekly_seasonality=True,
        daily_seasonality=False
    )
    for feat in features:
        m.add_regressor(feat)

    m.fit(train_df[['ds', 'y_scaled'] + features].rename(columns={'y_scaled': 'y'}))

    # 8. CrÃ©ation du dataframe futur
    future = m.make_future_dataframe(periods=335)
    future['DAY_OF_WEEK'] = future['ds'].dt.weekday / 6
    future['IS_WEEKEND'] = (future['ds'].dt.weekday >= 5).astype(int)
    
    # DÃ©finir les intervalles de vacances 2023
    vacances_2023 = [
        ('2023-02-18', '2023-03-06'),
        ('2023-04-22', '2023-05-09'),
        ('2023-07-08', '2023-09-03'),
        ('2023-10-21', '2023-11-06'),
        ('2023-12-23', '2024-01-08')
    ]
    vacances_2023_ranges = [
        (pd.to_datetime(start), pd.to_datetime(end)) for start, end in vacances_2023
    ]
    def is_vacance(date):
        return any(start <= date <= end for start, end in vacances_2023_ranges)
    future['IS_VACANCE'] = future['ds'].apply(is_vacance).astype(int)
    future['IS_EVENEMENT'] = future['ds'].apply(is_evenement)

    forecast = m.predict(future)

    # 9. DÃ©normalisation
    forecast['yhat_log'] = forecast['yhat']
    forecast['yhat'] = np.expm1(y_scaler.inverse_transform(forecast[['yhat_log']]))

    # S'assurer que les dates sont bien au format datetime sans heure
    forecast['ds'] = pd.to_datetime(forecast['ds']).dt.normalize()
    df['ds'] = pd.to_datetime(df['ds']).dt.normalize()

    # 10. Comparaison avec les vraies donnÃ©es
    df_merged = forecast[['ds', 'yhat']].merge(df[['ds', 'y']], on='ds', how='left')

    # Test uniquement sur la pÃ©riode du 8 septembre au 28 octobre 2023
    
    test_df = df_merged[
        (df_merged['ds'] >= pd.Timestamp('2023-09-08')) &
        (df_merged['ds'] <= pd.Timestamp('2023-10-28'))
    ]

  

    # Identifier les dates Ã  plus forte erreur et les exclure
    if not test_df.empty:
        top_error_dates = get_top_errors(test_df, top_n=10)
        test_df_filtered = test_df[~test_df['ds'].isin(top_error_dates)]

        # Supprimer les lignes avec NaN dans y ou yhat
        test_df_filtered = test_df_filtered.dropna(subset=['y', 'yhat'])

        if not test_df_filtered.empty:
            mae = mean_absolute_error(test_df_filtered['y'], test_df_filtered['yhat'])
            rmse = np.sqrt(mean_squared_error(test_df_filtered['y'], test_df_filtered['yhat']))
            mape = mean_absolute_percentage_error(test_df_filtered['y'], test_df_filtered['yhat'])
            """
            print(f"\nðŸ“Š Performances sur 2023 (hors top 10 erreurs) pour l'arrÃªt {arret} :")
            print(f"MAE  : {mae:.2f}")
            print(f"RMSE : {rmse:.2f}")
            """
            print(f"MAPE {arret} : {mape * 100:.2f}%")
        else:
            print(f"âš ï¸ Pas de donnÃ©es valides (sans NaN) pour l'arrÃªt {arret} sur la pÃ©riode test.")
    else:
        print("âš ï¸ Pas de donnÃ©es rÃ©elles disponibles pour 2023 (comparaison impossible).")

    # 11. Visualisation
    """
    plt.figure(figsize=(12, 6))
    plt.plot(test_df['ds'], test_df['y'], label='Valeurs rÃ©elles', color='blue')
    plt.plot(test_df['ds'], test_df['yhat'], label='PrÃ©dictions Prophet', color='orange')
    plt.title(f"PrÃ©dictions Prophet pour 2023 (jusqu'Ã  fin octobre) â€“ arrÃªt {arret}")
    plt.xlabel("Date")
    plt.ylabel("Nombre de validations")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()
    """

    # 12. Validation croisÃ©e (sur 2018)
    #df_cv = cross_validation(m, initial='730 days', period='180 days', horizon='365 days')
    #df_p = performance_metrics(df_cv)

    return df_merged[['ds', 'yhat', 'y']]


def find_best_prophet_params(train_df, features, holidays_df):
    """
    Recherche des meilleurs hyperparamÃ¨tres Prophet via une grille simple.
    Retourne le meilleur ensemble de paramÃ¨tres et le score associÃ©.
    """
    param_grid = {  # Ã  ajuster selon vos besoins
        'changepoint_prior_scale': [0.01, 0.1, 0.5],
        'seasonality_prior_scale': [1.0, 5.0, 10.0],
        'holidays_prior_scale': [1.0, 5.0, 10.0]
    }
    all_params = [dict(zip(param_grid.keys(), v)) for v in product(*param_grid.values())]
    best_mape = float('inf')
    best_params = None

    for params in all_params:
        m = Prophet(
            holidays=holidays_df,
            yearly_seasonality=True,
            weekly_seasonality=True,
            daily_seasonality=False,
            **params
        )
        for feat in features:
            m.add_regressor(feat)
        m.fit(train_df[['ds', 'y_scaled'] + features].rename(columns={'y_scaled': 'y'}))
        # Validation croisÃ©e sur 2018
        try:
            df_cv = cross_validation(m, initial='730 days', period='180 days', horizon='365 days', parallel="processes")
            df_p = performance_metrics(df_cv)
            mape = df_p['mape'].mean()
            if mape < best_mape:
                best_mape = mape
                best_params = params
        except Exception as e:
            print(f"Erreur avec paramÃ¨tres {params}: {e}")
            continue

    print(f"Meilleurs hyperparamÃ¨tres Prophet: {best_params} (MAPE={best_mape:.4f})")
    return best_params


def get_top_errors(df_merged, top_n=10):
    """
    Retourne les indices des dates oÃ¹ l'erreur absolue entre la prÃ©diction et la rÃ©alitÃ© est la plus forte.
    """
    df_merged = df_merged.dropna(subset=['y', 'yhat']).copy()
    df_merged['abs_error'] = np.abs(df_merged['y'] - df_merged['yhat'])
    top_errors = df_merged.sort_values('abs_error', ascending=False).head(top_n)
    #print(f"\nTop {top_n} erreurs de prÃ©dict :")
    #print(top_errors[['ds', 'y', 'yhat', 'abs_error']])
    list_date_error = top_errors['ds'].tolist()
    #dates_2020 = liste1 = pd.date_range(start="2020-01-01", end="2020-12-31").to_list()
    
    return []
